<!DOCTYPE html>
<html>
<head>
    <title>AudioWorklet Audio Streaming Test</title>
    <script src="/socket.io/socket.io.js"></script>
</head>
<body>
<button id="start">Start Recording</button>
<button id="stop" disabled>Stop Recording</button>
<div id="transcriptions">
    <!-- Transcriptions will be inserted here -->
</div>
<script>
    const startButton = document.getElementById('start');
    const stopButton = document.getElementById('stop');

    let socket, audioContext, workletNode, stream, input;

    startButton.addEventListener("click", startRecording);
    stopButton.addEventListener("click", stopRecording);

    // Starts the recording process
    async function startRecording() {
        startButton.disabled = true;
        stopButton.disabled = false;

        socket = io();
        audioContext = new AudioContext({ sampleRate: 44100});
        await audioContext.audioWorklet.addModule('audio-worklet-processor.js');

        // When a transcript is received, append it to the 'transcriptions' div
        socket.on('transcript', function(transcript) {
            const transcriptionsDiv = document.getElementById('transcriptions');
            const p = document.createElement('p');
            p.textContent = transcript;
            transcriptionsDiv.appendChild(p);
        });

        audioContext.resume().then(() => {
            console.log(audioContext.sampleRate);
            navigator.mediaDevices.getUserMedia({ video: false, audio: true })
                .then(handleMicStream)
                .catch(err => alert('Error accessing microphone: ' + err.message));
        });
    }

    // Handles microphone stream
    function handleMicStream(streamObj) {
        stream = streamObj;
        input = audioContext.createMediaStreamSource(stream);
        workletNode = new AudioWorkletNode(audioContext, 'audio-processor');
        input.connect(workletNode);

        workletNode.port.onmessage = (event) => {
            if (event.data.type === 'micBinaryStream') {
                socket.emit('micBinaryStream', event.data.payload);
            }
        };
    }

    function stopRecording() {
        stopButton.disabled = true;
        startButton.disabled = false;

        if (socket) {
            socket.disconnect();
            socket = null;
        }

        closeAll();
    }

    function closeAll() {
        if (stream) {
            const track = stream.getTracks()[0];
            if (track) track.stop();
        }

        if (workletNode) {
            workletNode.port.close();
            workletNode.disconnect();
            workletNode = null;
        }

        if (input) {
            input.disconnect();
            input = null;
        }

        if (audioContext) {
            audioContext.close().then(() => {
                audioContext = null;
            });
        }
    }
</script>
</body>
</html>
